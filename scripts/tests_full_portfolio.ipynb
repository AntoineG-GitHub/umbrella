{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for nan...\n",
      "Error fetching price data for nan: {\"status\": \"error\", \"message\": \"'Time Series FX (Daily)'\"}\n",
      "Fetching data for RITM...\n",
      "Successfully fetched price data for RITM\n",
      "Fetching data for CRM...\n",
      "Successfully fetched price data for CRM\n",
      "Fetching data for NVDA...\n",
      "Successfully fetched price data for NVDA\n",
      "Fetching data for SPYD.DE...\n",
      "Error fetching price data for SPYD.DE: {\"status\": \"error\", \"message\": \"'Time Series FX (Daily)'\"}\n",
      "Fetching data for MSFT...\n",
      "Successfully fetched price data for MSFT\n",
      "Fetching data for SGLD...\n",
      "Error fetching price data for SGLD: {\"status\": \"error\", \"message\": \"'Time Series (Daily)'\"}\n",
      "Fetching data for WIX...\n",
      "Error fetching price data for WIX: {\"status\": \"error\", \"message\": \"'Time Series (Daily)'\"}\n",
      "Fetching data for AMD...\n",
      "Error fetching price data for AMD: {\"status\": \"error\", \"message\": \"'Time Series (Daily)'\"}\n",
      "Completed fetching all required data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Load the transactions data\n",
    "df = pd.read_excel('../notebooks/cleaned_transactions_processed.xlsx')\n",
    "\n",
    "# Get unique tickers and currencies\n",
    "unique_tickers = df['ticker'].unique()\n",
    "\n",
    "# Base URL for the API endpoints\n",
    "base_url = 'http://localhost:8000'\n",
    "\n",
    "# response = requests.get(f\"{base_url}/data_ingestion/fetch_and_save_data_exchange_rate/USD/\")\n",
    "# if response.status_code == 200:\n",
    "#     print(f\"Successfully fetched exchange rates for USD\")\n",
    "# else:\n",
    "#     print(f\"Error fetching exchange rates for USD: {response.text}\")\n",
    "\n",
    "# Fetch data for each ticker\n",
    "for ticker in unique_tickers:\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    \n",
    "    # Call endpoint to fetch and save daily prices\n",
    "    response = requests.get(f\"{base_url}/data_ingestion/fetch_and_save_data/{ticker}/\")\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Successfully fetched price data for {ticker}\")\n",
    "    else:\n",
    "        print(f\"Error fetching price data for {ticker}: {response.text}\")\n",
    "    \n",
    "    # Add delay to avoid hitting API rate limits\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"Completed fetching all required data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success: sell on 2024-07-12 (36.08 EUR)\n",
      "✅ Success: sell on 2024-07-12 (505.13 EUR)\n",
      "✅ Success: buy on 2022-05-30 (-510.39 EUR)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Path to your Excel file\n",
    "EXCEL_FILE = \"../notebooks/cleaned_transactions_processed.xlsx\"  # update if needed\n",
    "API_URL = \"http://localhost:8000/transactions/create/\"  # update if deployed\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "\n",
    "df = pd.read_excel(EXCEL_FILE)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if row[\"ticker\"] == \"SXLP.MI\":\n",
    "        # Format and clean up data\n",
    "        payload = {\n",
    "            \"type\": row[\"type\"],\n",
    "            \"amount\": (row[\"amount\"]),\n",
    "            \"date\": row[\"date\"].strftime(\"%Y-%m-%d\") if isinstance(row[\"date\"], (pd.Timestamp, datetime)) else row[\"date\"],\n",
    "            \"user_id\": int(row[\"user_id\"]) if not pd.isna(row[\"user_id\"]) else None,\n",
    "            \"ticker\": row[\"ticker\"] if pd.notna(row[\"ticker\"]) else None,\n",
    "            \"shares\": float(row[\"shares\"]) if pd.notna(row[\"shares\"]) else None,\n",
    "            \"metadata\": json.loads(row[\"metadata\"]) if isinstance(row[\"metadata\"], str) and row[\"metadata\"].strip().startswith(\"{\") else {}\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "            if response.status_code == 201:\n",
    "                print(f\"✅ Success: {payload['type']} on {payload['date']} ({payload['amount']} EUR)\")\n",
    "            else:\n",
    "                print(f\"❌ Error {response.status_code} - {response.text} - Data: {payload}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Exception for row: {payload} -> {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umbrella",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
